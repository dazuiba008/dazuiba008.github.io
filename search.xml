<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Greenplum install]]></title>
    <url>%2F2013%2F09%2F18%2FGreenplum-install%2F</url>
    <content type="text"><![CDATA[架构：master主要建立与客户端的连接，收集segment的执行结果，不存放业务数据，可以一主一备segment业务数据存放处，执行master分发的SQL,一台机器可以配置多个segment，segment分primary和mirror 四台服务器搭建测试环境 192.168.101.115 master192.168.101.116 segment+standby192.168.100.217 segment192.168.100.225 segment 分辨配置一个primary，一个mirror对应后面参数路径，如果设置多个,空格分隔即可declare -a DATA_DIRECTORY=(/data01/gpadmin/gpdata/primary)declare -a MIRROR_DATA_DIRECTORY=(/data01/gpadmin/gpdata/mirror) 1.每台服务器/etc/hosts192.168.101.115 db-192-168-101-115.sky-mobi.com db-192-168-101-115192.168.101.116 db-192-168-101-116.sky-mobi.com db-192-168-101-116192.168.100.217 db-192-168-100-217.sky-mobi.com db-192-168-100-217192.168.100.225 db-192-168-100-225.sky-mobi.com db-192-168-100-225 2.配置/etc/sysctl.confkernel.shmmax = 500000000kernel.shmmni = 4096kernel.shmall = 4000000000kernel.sem = 250 512000 100 2048kernel.sysrq = 1kernel.core_uses_pid = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.msgmni = 2048net.ipv4.tcp_syncookies = 1net.ipv4.conf.default.accept_source_route = 0net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_max_syn_backlog = 4096net.ipv4.conf.all.arp_filter = 1net.ipv4.ip_local_port_range = 10000 65535net.core.netdev_max_backlog = 10000net.core.rmem_max = 2097152net.core.wmem_max = 2097152vm.overcommit_memory = 2 3.配置/etc/security/limits.conf soft nofile 65536 hard nofile 65536 soft nproc 131072 hard nproc 131072 修改磁盘调度策略echo deadline &gt; /sys/block/sba/queue/scheduler 5.执行安装程序useradd gpadminpasswd gpadminunzip greenplum-db-4.3.12.0-rhel5-x86_64.zip./greenplum-db-4.3.12.0-rhel5-x86_64.bin默认安装在/usr/local下 7.chown -R gpadmin.gpadmin /usr/local/greenplum-db8.配置gpadmin环境变量，添加以下source /usr/local/greenplum-db/greenplum_path.shexport MASTER_DATA_DIRECTORY=/data01/gpadmin/gpdata/master/gpseg-1export PGPORT=1922export PS1=”$USER@/bin/hostname -s-&gt; “ 9.新建两个文件hostlist, seg_hostshostlistdb-192-168-101-115db-192-168-101-116db-192-168-100-217db-192-168-100-225 seg_hostsdb-192-168-101-116db-192-168-100-217db-192-168-100-225 10.使用gpssh-exkeys打通所有服务器的透明登陆gpssh-exkeys -f hostlistgpssh -f hostlist ls //批量执行命令 11.打包安装好的目录，并复制到其他节点，解压tar -cf gp.tar /use/local/greenplum-db-4.3.12.0/gpscp -f hostlist gp.tar =:/home/gpmadin //批量服务到每个节点tar -xf gp.tar //解压 12.建立相关数据目录赋予权限mkdir -p /data01/gpadmin/gpdata/mastermkdir -p /data01/gpadmin/gpdata/primarymkdir -p /data01/gpadmin/gpdata/mirrorchown -R gpadmin.gpadmin /data01/gpadmin/gpdata/master /data01/gpadmin/gpdata/primary /data01/gpadmin/gpdata/mirror 13.初始化Greenplum复制配置文件到自己的目录cp /usr/local/greenplum-db/docs/cli_help/gpconfigs/gpinitsystem_config /home/gpadmin/ 修改后的相关参数ARRAY_NAME=”SKY Greenplum DW”SEG_PREFIX=gpsegPORT_BASE=40000declare -a DATA_DIRECTORY=(/data01/gpadmin/gpdata/primary)MASTER_HOSTNAME=db-192-168-101-115MASTER_DIRECTORY=/data01/gpadmin/gpdata/masterMASTER_PORT=1922TRUSTED_SHELL=sshCHECK_POINT_SEGMENTS=8ENCODING=UTF-8MIRROR_PORT_BASE=50000REPLICATION_PORT_BASE=41000MIRROR_REPLICATION_PORT_BASE=51000declare -a MIRROR_DATA_DIRECTORY=(/data01/gpadmin/gpdata/mirror)MACHINE_LIST_FILE=/home/gpadmin/seg_hosts 初始化GPgpinitsystem -c /home/gpadmin/gpinitsystem_config -s db-192-168-101-116 数据库可以正常连接：psql -d postgrespsql (8.2.15)Type “help” for help. postgres=# \l List of databases Name | Owner | Encoding | Access privileges———–+———+———-+———————— hank | gpadmin | UTF8 | =Tc/gpadmin : gpadmin=CTc/gpadmin : hank=CTc/gpadmin postgres | gpadmin | UTF8 | template0 | gpadmin | UTF8 | =c/gpadmin : gpadmin=CTc/gpadmin template1 | gpadmin | UTF8 | =c/gpadmin : gpadmin=CTc/gpadmin 关闭与启动： gpstart -a 启动 gpstop -a 关闭 gpstop -r 重启 gpstop -u 重载配置参数 gpstart -m 单用户维护模式启动 PGOPTIONS=’-c gp_session_role=utility’ psql gpstate 查看GP状态 参考：http://gpdb.docs.pivotal.io/43120/install_guide/prep_os_install_gpdb.html]]></content>
      <categories>
        <category>Greenplum</category>
      </categories>
      <tags>
        <tag>Greenplum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb replica sets reconfig and conver a Secondary to an Arbiter]]></title>
    <url>%2F2013%2F04%2F22%2Fmongodb-replica-sets-reconfig-and-conver-a-Secondary-to-an-Arbiter%2F</url>
    <content type="text"><![CDATA[replica set由于需求可能会调整节点的优先级，或者仲裁节点那么先看一下语法：rs.reconfig(configuration[, force])Parameters:configuration – A document that specifies the configuration of a replica set.force – Optional. Specify { force: true } as the force parameter to force the replica set to accept the new configuration even if a majority of the members are not accessible. Use with caution, as this can lead to rollback situations.Initializes a new replica set configuration. This function will disconnect the shell briefly and forces a reconnection as the replica set renegotiates which node will be primary. As a result, the shell will display an error even if this command succeeds. rs.reconfig() provides a wrapper around the “replSetReconfig” database command. rs.reconfig() overwrites the existing replica set configuration. Retrieve the current configuration object with rs.conf(), modify the configuration as needed and then use rs.reconfig() to submit the modified configuration object. To reconfigure a replica set, use the following sequence of operations: conf = rs.conf() // modify conf to change configuration rs.reconfig(conf)If you want to force the reconfiguration if a majority of the set isn’t connected to the current member, or you’re issuing the command against a secondary, use the following form: conf = rs.conf() // modify conf to change configuration rs.reconfig(conf, { force: true } )Warning Forcing a rs.reconfig() can lead to rollback situations and other difficult to recover from situations. Exercise caution when using this option.这里遇到rollback情况，可能会导致fatal状态，那么replica set就等于失效了，可以拷贝local数据文件，或者所有数据文件进行重建举例：var c = rs.conf();c.members[2].priority = 0; 0~100数字越大优先级越高，0不会被切换为primary节点，这里也可以写成包含小数的值rs.reconfig(c);配置完以后，可以通过一下命令查看一下配置是否修改好：rs.conf()rs.status()为了防止脑裂，可以加入仲裁节点，使用以下命令：rs.addArb(“:&lt;:port&gt;”); ==rs.add(hostspec, arbiterOnly)示例：rs.add(‘mongodb3.example.net:27017’, true)当然将一个从节点转换为仲裁节点：(1)首先关闭从节点(2)rs.remove(“&lt;:port&gt;”)删除该从节点，rs.conf()验证一下(3)创建新的数据目录，因为仲裁节点是不存放生产数据的(4)通过rs.addArb(“:&lt;:port&gt;”)加入，rs.conf()验证一下那么就可以看到：仲裁节点的属性为”arbiterOnly” : true{ “_id” : “xxx”, “version” : 14, “members” : [ { “_id” : 1, “host” : “xxx.xxx.xxx.xxx:5281” }, { “_id” : 2, “host” : “ xxx.xxx.xxx.xxx :5281”, “arbiterOnly” : true }, { “_id” : 3, “host” : “ xxx.xxx.xxx.xxx :5281” } ]}]]></content>
      <categories>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[来自francs的PG锁浅析，可以和oracle锁对照区别一下]]></title>
    <url>%2F2011%2F11%2F10%2F%E6%9D%A5%E8%87%AAfrancs%E7%9A%84PG%E9%94%81%E6%B5%85%E6%9E%90%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%92%8Coracle%E9%94%81%E5%AF%B9%E7%85%A7%E5%8C%BA%E5%88%AB%E4%B8%80%E4%B8%8B%2F</url>
    <content type="text"><![CDATA[一、概述此文档主要对Postgresql 锁机制进行分析，在讲解的过程中结合实验，理解Postgresql的锁机制。 二、表级锁类型表级锁类型分为八种，以下对各种表级锁类型进行简单介绍下, 锁的冲突模式可以参考3.1的图一:表级锁冲突模式。 2.1 ACCESS SHARE“ACCESS SHARE”锁模式只与“ACCESS EXCLUSIVE” 锁模式冲突; 查询命令（Select command）将会在它查询的表上获取”Access Shared” 锁,一般地，任何一个对表上的只读查询操作都将获取这种类型的锁。 ##2.2 ROW SHARE “Row Share” 锁模式与”Exclusive’和”Access Exclusive”锁模式冲突; ”Select for update”和”Select for share”命令将获得这种类型锁，并且所有被引用但没有 FOR UPDATE 的表上会加上”Access shared locks”锁。 2.3 ROW EXCLUSIVE “Row exclusive” 与 “Share,Shared roexclusive,Exclusive,Access exclusive”模式冲突; “Update,Delete,Insert”命令会在目标表上获得这种类型的锁，并且在其它被引用的表上加上”Access shared”锁,一般地，更改表数据的命令都将在这张表上获得”Row exclusive”锁。 2.4 SHARE UPDATE EXCLUSIVE”Share update exclusive,Share,Share row ,exclusive,exclusive,Access exclusive”模式冲突，这种模式保护一张表不被并发的模式更改和VACUUM; “Vacuum(without full), Analyze ”和 “Create index concurrently”命令会获得这种类型锁。 2.5 SHARE与“Row exclusive,Shared update exclusive,Share row exclusive ,Exclusive,Access exclusive”锁模式冲突,这种模式保护一张表数据不被并发的更改; “Create index”命令会获得这种锁模式。 2.6 SHARE ROW EXCLUSIVE与“Row exclusive,Share update exclusive,Shared,Shared row exclusive,Exclusive,Access Exclusive”锁模式冲突; 任何Postgresql 命令不会自动获得这种锁。 2.7 EXCLUSIVE与” ROW SHARE, ROW EXCLUSIVE, SHARE UPDATE EXCLUSIVE, SHARE, SHARE ROW EXCLUSIVE, EXCLUSIVE, ACCESS EXCLUSIVE”模式冲突,这种索模式仅能与Access Share 模式并发,换句话说，只有读操作可以和持有”EXCLUSIVE”锁的事务并行； 任何Postgresql 命令不会自动获得这种类型的锁； 2.8 ACCESS EXCLUSIVE与所有模式锁冲突(ACCESS SHARE, ROW SHARE, ROW EXCLUSIVE, SHARE UPDATE EXCLUSIVE, SHARE, SHARE ROW EXCLUSIVE, EXCLUSIVE, and ACCESS EXCLUSIVE),这种模式保证了当前只有一个事务访问这张表; “ALTER TABLE, DROP TABLE, TRUNCATE, REINDEX, CLUSTER, VACUUM FULL” 命令会获得这种类型锁，在Lock table 命令中，如果没有申明其它模式，它也是缺省模式。 三、表级锁冲突模式3.1 Conflicting lock modes 图一 表级锁冲突模式备注： 上图是Postgresql 表级锁的各种冲突模式对照表，红色的‘X’表示冲突项, 在章节四中会对其中典型的锁模式进行模似演示。 四、实验在这一章节中将会对图一中比较典型的锁冲突进行模似演练，了解这些在Postgresql DBA的日常维护工作中很有帮助，同时也能减少人为故障的发生。 4.1 Access exclusive 锁与Access share锁冲突 在日常维护中，大家应该执行过’ALTER TABLE’更改表结构的DDL，例如加字段，更改字段数据类型等，根据章节二的理论，在执行’ALTER TABLE’命令时将申请一个Access exclusive锁, 根据图一，大家知道Access exclusive 锁和所有的锁模式都冲突，那么，它将会’Select’命令冲突，因为Select 加的是Access share锁，那么真的会与‘SELECT‘命令冲突吗，接下来给大家演示下: –创建一张测试表 test_2 并插入测试数据 mydb=&gt; create table test_2 (id integer,name varchar(32)); CREATE TABLE mydb=&gt; insert into test_2 values (1,’franc’); INSERT 0 1 mydb=&gt; insert into test_2 values (2,’tan’); INSERT 0 1 mydb=&gt; select * from test_2; id | name —-+——- 1 | franc 2 | tan (2 rows) –会话一 查询表数据 ( 这里获得Access Shared 锁) mydb=&gt; begin; BEGIN mydb=&gt; select * from test_2 where id=1; id | name —-+——- 1 | franc (1 row) 注意：这里begin开始事务，没有提交； –会话二 更改表结构 (这里申请 Access Exclusive锁 ) mydb=&gt; alter table test_2 add column sex char(1); 发现，命令一直等侍，执行不下去; –会话三 查询状态 mydb=# select oid,relname from pg_class where relname=’test_2’; oid | relname ——-+——— 33802 | test_2 mydb=# select locktype,database,relation,pid,mode from pg_locks where relation=’33802’; locktype | database | relation | pid | mode ———-+———-+———-+——-+——————— relation | 16466 | 33802 | 18577 | AccessShareLock relation | 16466 | 33802 | 18654 | AccessExclusiveLock mydb=# select datname,procpid,usename,current_query from pg_stat_activity where procpid in (18577,18654); datname | procpid | usename | current_query ———+———+———+——————————————– mydb | 18577 | skytf | in transaction mydb | 18654 | skytf | alter table test_2 add column sex char(1); (2 rows) 这里可以看出会话一(pid=18577) 获取的是 “AccessShareLock”锁, 会话二(pid=18654 ) 获取的是 “AccessExclusiveLock”锁。 –再次回到会话一，执行’end’结束事务后会发生什么结果 注意，此时会话二还处于等侍状态 mydb=&gt; end; COMMIT –回到会话二发现 原来处于等侍状态的’ALTER TABLE’命令执行成功 mydb=&gt; alter table test_2 add column sex char(1); ALTER TABLE mydb=&gt; \d test_2 Table &quot;skytf.test_2&quot; Column | Type | Modifiers ——–+———————–+———– id | integer | name | character varying(32) | sex | character(1) | –回到会话三，锁已经释放 mydb=# select locktype,database,relation,pid,mode from pg_locks where relation=’33802’; locktype | database | relation | pid | mode ———-+———-+———-+—–+—— (0 rows) mydb=# select datname,procpid,usename,client_addr,current_query from pg_stat_activity where procpid in (18577,18654); datname | procpid | usename | client_addr | current_query ———+———+———+————-+————— mydb | 18577 | skytf | | mydb | 18654 | skytf | | (2 rows) 实验说明： 这个实验说明了 ‘ALTER TABLE’命令与’SELECT’命令会产生冲突，证实了开始的结论，即”Access exclusive”锁模式与申请”Access shared”锁模式的’SELECT’命令相冲突。 4.2 Share 锁与 Row Exclusive 锁冲突在数据库的维护过程中，创建索引也是经常做的工作，别小看创建索引，如果是一个很繁忙的系统，索引不一定能创建得上，可能会发生等侍, 严重时造成系统故障；根据章节二的理论，’Create Index’ 命令需要获取Share 锁模式。 根据图一，”Share” 锁和”Row Exclusive”锁冲突，下面来验证一下： 根据图三可以看出，share锁模式和多种锁模式冲突，有可能会问我，为什么单独讲share锁和Row Exclusive冲突呢？因为” Update,Delete,Insert”命令获取的是Row Exclusive 操作，而这种操作在生产过程中非常频繁；这个实验正是模似生产维护过程。 –会话一， 向 test_2 上插入一条数据 mydb=&gt; select * from test_2; id | name | sex —-+——-+—– 1 | franc | 2 | tan | (2 rows) mydb=&gt; begin; BEGIN mydb=&gt; insert into test_2 values (3,’fpzhou’); INSERT 0 1 mydb=&gt; 说明： 这个Insert 操作放在一个事务里，注意此时事务尚未提交。 –会话二，在表test_2上创建索引 mydb=&gt; \d test_2; Table &quot;skytf.test_2&quot; Column | Type | Modifiers ——–+———————–+———– id | integer | name | character varying(32) | sex | character(1) | mydb=&gt; create unique index idx_test_2_id on test_2 (id); 说明： 创建索引命令发生等侍 –会话三，查询状态 mydb=# select locktype,database,relation,pid,mode from pg_locks where relation=’33802’; locktype | database | relation | pid | mode ———-+———-+———-+——-+—————— relation | 16466 | 33802 | 18577 | RowExclusiveLock relation | 16466 | 33802 | 18654 | ShareLock (2 rows) mydb=# select datname,procpid,usename,client_addr,current_query from pg_stat_activity where procpid in (18577,18654); datname | procpid | usename | client_addr | current_query ———+———+———+————-+—————————————————- mydb | 18577 | skytf | | in transaction mydb | 18654 | skytf | | create unique index idx_test_2_id on test_2 (id); 说明： 这里可以看出”Insert into”(procpid=18577) 命令获取”RowExclusiveLock”,而”Create Index”(procpid=18654)操作获取的是”Sharelock”, 并且创建索引操作发了等侍，因为这两种锁模式是冲突的。 –回到会话一，提交事务,看看会发生什么 注意，此时创建索引的会话二仍处于等侍状态 mydb=&gt; end; COMMIT –回到会话二，发现创建索引命令成功,等侍消失 mydb=&gt; create unique index idx_test_2_id on test_2 (id); CREATE INDEX 实验结论：1 上述实验说明 “Create index “操作和”Insert”操作冲突;也 就是 “Share”锁和”RowExclusive”锁冲突。 2 在生产库上应该避免在业务高峰期执行新建索引操作，因 为如果在张大表上新建索引，消耗时间较长，在这个过程中会阻塞业务的DML操作。 4.3 SHARE UPDATE EXCLUSIVE 与自身冲突 根据章节二，大家知道 VACUUM(Without full), Analyze 和 Create index (Concurently)操作会申请获得”Shared update Exclusive 锁”。根据图一，”Shared update Exclusive 锁”与本身也是会冲突的，下面实验验证一下: –会话一，分析表test_2 mydb=&gt; select * from test_2; id | name | sex —-+——–+—– 1 | franc | 2 | tan | 3 | fpzhou | (3 rows) mydb=&gt; mydb=&gt; mydb=&gt; begin; BEGIN mydb=&gt; analyze test_2; ANALYZE 注意： 表分析放在一个事务里，此时并没有提交； –会话二 对表 test_2 做 vacuum mydb=&gt; \d test_2; Table &quot;skytf.test_2&quot; Column | Type | Modifiers ——–+———————–+———– id | integer | name | character varying(32) | sex | character(1) | Indexes: &quot;idx_test_2_id&quot; UNIQUE, btree (id) mydb=&gt; vacuum test_2; 注意： 当对表 test_2 执行 vacuum操作时，操作等侍， –会话三，观察系统哪里锁住了 [postgres@pg1 ~]$ psql -d mydb psql (9.0beta3) Type “help” for help. mydb=# select datname,procpid,waiting,current_query from pg_stat_activity where waiting=’t’; datname | procpid | waiting | current_query ———+———+———+—————- mydb | 20625 | t | vacuum test_2; (1 row) 这里说明会话 vacuum test_2 在等侍 mydb=# select oid,relname from pg_class where relname=’test_2’; oid | relname ——-+——— 33802 | test_2 (1 row) mydb=# select locktype,database,relation,pid,mode from pg_locks where relation=’33802’; locktype | database | relation | pid | mode ———-+———-+———-+——-+————————– relation | 16466 | 33802 | 20625 | ShareUpdateExclusiveLock relation | 16466 | 33802 | 20553 | ShareUpdateExclusiveLock (2 rows) 说明: 这里可以看出 ‘Analyze’操作 (pid=20553) 和’Vacuum’操作 (pid=20625)都是加的”ShareUpdateExclusiveLock”。 mydb=# select datname,procpid,waiting,current_query from pg_stat_activity where procpid in (20625,20553); datname | procpid | waiting | current_query ———+———+———+———————– mydb | 20553 | f | in transaction mydb | 20625 | t | vacuum test_2; (2 rows) 说明： 结束上面查询可以看出会话20625在等侍会话20553,也就是说”vacuum test_2” 被事务堵住了， –再次回到会话一，提交会话,注意此时会话二处于等侍姿态； mydb=&gt; end; COMMIT –再次回到会话二，发现 vacuum命令执行下去了，等侍消失。 mydb=&gt; vacuum test_2; VACUUM mydb=&gt; select datname,procpid,waiting,current_query from pg_stat_activity where waiting=’t’; datname | procpid | waiting | current_query ———+———+———+————— (0 rows) 实验结论 1 Analyze 和 Vacuum 操作都会申请获得 “ShareUpdateExclusiveLock”。 2 ShareUpdateExclusiveLoc与ShareUpdateExclusiveLock是冲突的。]]></content>
      <categories>
        <category>PostgreSQL</category>
      </categories>
      <tags>
        <tag>PostgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[触发器限制指定IP访问oracle数据库]]></title>
    <url>%2F2011%2F09%2F21%2F%E8%A7%A6%E5%8F%91%E5%99%A8%E9%99%90%E5%88%B6%E6%8C%87%E5%AE%9AIP%E8%AE%BF%E9%97%AEoracle%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[最近有个项目需要限制某些数据库用户的访问来源IP，在PG中比较好实现，但是ORACLE没有比较简便的操作。如果不管用户的话，仅仅限制来源IP对监听的访问是比较容易实现的，通过配置数据库服务器的sqlnet.ora文件或者修改数据库服务器的IPTABLES等手段实现。123456789101112131415161718192021222324252627sqlnet.ora范例:tcp.validnode_checking=yestcp.invited_nodes=(172.16.33.11,172.16.34.89)iptables范例:[root@kefu ~]# cat /etc/sysconfig/iptables# Firewall configuration written by system-config-securitylevel# Manual customization of this file is not recommended.*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:RH-Firewall-1-INPUT - [0:0]-A INPUT -j RH-Firewall-1-INPUT-A FORWARD -j RH-Firewall-1-INPUT# 允许访问1521的服务器-A RH-Firewall-1-INPUT -s 172.16.3.68/32 -m state --state NEW -m tcp -p tcp --dport 1521 -j ACCEPT-A RH-Firewall-1-INPUT -i lo -j ACCEPT-A RH-Firewall-1-INPUT -p icmp --icmp-type any -j ACCEPT-A RH-Firewall-1-INPUT -p 50 -j ACCEPT-A RH-Firewall-1-INPUT -p 51 -j ACCEPT-A RH-Firewall-1-INPUT -p udp --dport 5353 -d 224.0.0.251 -j ACCEPT-A RH-Firewall-1-INPUT -p udp -m udp --dport 631 -j ACCEPT-A RH-Firewall-1-INPUT -p tcp -m tcp --dport 631 -j ACCEPT-A RH-Firewall-1-INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT-A RH-Firewall-1-INPUT -j REJECT --reject-with icmp-host-prohibitedCOMMIT 下面来看看如何限制特定用户和特定IP： 创建ACL表 (本例将ACL表建立在dsm用户下,随便建哪里都可以)1234create table dsm.tbl_iplimit (logonuser varchar2(32),ip_address varchar2(15),remark varchar2(64),create_time date default sysdate);insert into dsm.tbl_iplimit values (&apos;DSM&apos;,&apos;172.16.18.81&apos;,&apos;digoal&apos;&apos;s host.&apos;,sysdate);insert into dsm.tbl_iplimit values (&apos;DSM&apos;,&apos;local&apos;,&apos;本地&apos;,sysdate);commit; 这里限制了DSM用户只能从172.16.18.81和ORACLE所在服务器登录.其他用户不受限制. 创建触发器 1234567891011121314151617181920212223conn / as sysdbacreate or replace trigger &quot;logon_audit&quot; afterlogon on databasedeclarerecord_num number;userip varchar2(15);isforbidden boolean:=true;begin userip:=nvl(sys_context (&apos;userenv&apos;,&apos;ip_address&apos;),&apos;local&apos;); select count(*) into record_num from dsm.tbl_iplimit where logonuser=user; if (record_num&gt;0) then select count(*) into record_num from dsm.tbl_iplimit where logonuser=user and ip_address=userip; if (record_num=0) then raise_application_error(-20003,&apos;ip :&apos;||userip||&apos; is forbided&apos;); end if; end if;exception when value_error then sys.dbms_output.put_line(&apos;exception handed&apos;); when others then raise;end logon_audit;/ 测试 123456789101112131415161718192021222324在本地登录SQL&gt; conn dsm/pwd正常delete from tbl_iplimit where ip_address=&apos;local&apos;;commit;exit;再在本地登录,已经受阻了.SQL&gt; conn dsm/pwdERROR:ORA-00604: error occurred at recursive SQL level 1ORA-20003: ip :local is forbidedORA-06512: at line 18换台机器(172.16.3.67)登录:SQL&gt; conn dsm/pwd@//172.16.3.13:1521/sidERROR:ORA-00604: error occurred at recursive SQL level 1ORA-20003: ip :local is forbidedORA-06512: at line 18受阻换台机器(172.16.3.81)登录:SQL&gt; conn dsm/pwd@//172.16.3.13:1521/sid正常 如果IP范围比较宽，可以写一个IP比较的函数加入到上面的判断中,避免写很多条记录。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle执行计划和执行顺序]]></title>
    <url>%2F2011%2F09%2F21%2Foracle%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E5%92%8C%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[如果要了解执行计划和执行顺序，必须理解执行计划的父子关系。执行计划是一个树状结构，顶层的STATEMENT是这棵树的根。父子关系按照如下的树状结构组织：PARENT FIRST CHILD SECOND CHILD 在这个例子里，FIRST CHILD最先执行，然后是SECOND CHILD，这两个步骤执行完毕后，执行PARENT。下面是一个更多层次的结构： PARENT1 FIRST CHILD FIRST GRANDCHILD SECOND CHILD FIRST GRANDCHILD是第一个执行的步骤，然后是FIRST CHILD。下面通过一个真实的执行计划来验证这个原则： set autotrace traceonly explain select ename,dname from emp, dept where emp.deptno=dept.deptno and dept.dname in (‘ACCOUNTING’,’RESEARCH’,’SALES’,’OPERATIONS’); 15 rows selected. 这个语句的执行计划如下： Execution Plan 0 SELECT STATEMENT Optimizer=CHOOSE (Cost=3 Card=8 Bytes=248) 1 0 HASH JOIN (Cost=3 Card=8 Bytes=248) 2 1 TABLE ACCESS (FULL) OF ‘DEPT’ (Cost=1 Card=3 Bytes=36) 3 1 TABLE ACCESS (FULL) OF ‘EMP’ (Cost=1 Card=16 Bytes=304) 注意这个执行计划的最左边的两个列，第一个列是步骤的ID，第二个列是父步骤的ID。执行从ID=0的行开始： 0 SELECT STATEMENT Optimizer=CHOOSE (Cost=3 Card=8 Bytes=248) 这个步骤没有父步骤，有一个子步骤（ID=1），所以这个ID＝1的步骤必须在执行步骤0之前执行。继续观察ID=1的步骤： 1 0 HASH JOIN (Cost=3 Card=8 Bytes=248) 这个步骤是ID=0的步骤的子步骤，该步骤有2个子步骤：ID=2和ID=3，因此ID=2和ID=3的步骤必须在ID=1的步骤之前执行。再来检查ID=2的步骤： 2 1 TABLE ACCESS (FULL) OF ‘DEPT’ (Cost=1 Card=3 Bytes=36) 这个步骤是ID=1的步骤的子步骤，并且该步骤没有任何子步骤。因此该步骤是这个SQL语句第一个执行的步骤，这个步骤产生的结果集会提供给ID=1的步骤。这个步骤是对表DEPT进行全表扫描，这个步骤的COST＝1。 ID=1的步骤也依赖ID=3的步骤： 3 1 TABLE ACCESS (FULL) OF ‘EMP’ (Cost=1 Card=16 Bytes=304) 这个步骤是ID=1的步骤的第二个子步骤，没有任何子步骤，在这个语句中，是第二个被执行的步骤。 ID=1的步骤将ID=3和ID=3的步骤的结果集进行HASH 连接，然后把结果交给ID=0的步骤，就完成了本语句的执行。 这里是转载白鳝大大的一篇文章，对于执行计划读取入门，还是很清楚简单明了的。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈oracle索引]]></title>
    <url>%2F2011%2F09%2F21%2F%E6%B5%85%E8%B0%88oracle%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[oracle索引一般分为B树索引和位图索引，用的比较多的都是B树索引。 B树索引，比如普通索引，反转索引，降序索引，函数索引，这些索引都是B树索引，结构都是一样的，位图索引的存储结构和B树是不一样的，对于B树索引，可以进行一般的索引唯一扫描，索引范围扫描，快速索引扫描和索引全扫描，位图就简单很多，他只有全扫描，才能找到对应的行。顾名思义，B树索引其实就是一棵树，普通的都是升序，右边节点比左边的节点大，那么降序就是正好反之。B树的所有节点都在一条双向链上，就是用来实现范围扫秒用的。 接下来，介绍一下反转索引，反转索引在存储键值的时候，先把键值反转，再进行存储，比如abcd就反转为dcba，一般反转索引用来解决热块，原理就是利用键值反转，把索引块打乱，把热点分散到不同的索引块。 记得创建的时候是用reverse函数：create index_name on tablename (reverse(ind_name));如过是 create index_name on tablename(ind_name) reverse;是用不到范围扫描的。 HW大家应该都清楚，如果是全表扫描，那么所有的数据块都会被扫一遍，HW以下的是肯定被扫的，以上的就不用了，以上的就相当于是没人住过的房子，不用去找。这里B树索引高度一般都是3，就是说扫描三个索引块就可以找到值，如果数据量大，那么可能就会高于3这个高度，B索引重要的几个概念，根节点，分支节点，叶子节点，很好理解，根肯定是最高的，分支就在中间，叶子在最底层，这里注意叶子节点，他除了有键值，还有块地址。 还有一点索引的使用绝对不能滥用，因为索引是有序的，所以在IO上会有很大消耗，如果一个表上很多索引，而且表的内容经常使用DML语句，那么索引肯定也是经常更新，会消耗额外的IO和CPU性能。还有一点一定要记得，创建好函数索引以后，一定要记得分析后再使用。至于反转索引，这里不详解了，可以dump出来看看，在reverse一下看看区别。很明显。 还有索引快速扫和索引扫是不一样的，快速只扫叶子节点，一次性读取db_file_multiblock_read_count个，索引扫是从根开始扫，只读书一个数据块。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[library cache]]></title>
    <url>%2F2011%2F09%2F21%2Flibrary-cache%2F</url>
    <content type="text"><![CDATA[这里简单发表下对库告诉缓存的认识，大家知道共享池是有library cache和data dictionary cache和控制部分组成，首先sql执行的过程显示语法分析阶段，然后是语意分析阶段，也就是验证下对象权限等一些列的东西，再下面就是SQL进行hash运算，运算后匹配library cache里的hash桶，再匹配hash桶上面的handle，也就是句柄，如果匹配成功，那么去找子游标，如果不成功，那么就生成一个handle，这里也就是硬解析，挂载hash桶上。 这里如果是不同用户或者，期间对象权限更改，就算是SQL文本一样，也是无法共享子游标的，生成handle，其实就是要想共享池申请空闲的内存，期间获得shared pool latch ，那么很容易产生冲突。handle其实就是存放的父游标，真正的执行计划是存放在子游标上的，也就是heap6上，一个父游标可能对应多个子游标，比如，不同用户下的相同SQL，就会造成1个父对多个子游标，这种父游标存在，而要重新生成子游标，就是relaod，需要耗硬件资源，数据库性能也就十分低下，所以我们要避免硬解析和reload，解析过程中很消耗资源，而且容易造成 latch的冲突，父游标里主要包含SQL文本，父游标打开时，是被锁住的，也就是不能交换出library cache ，子游标主要包含执行计划和绑定变量，这个就很重要。这里再介绍下软解析，其实只要在hash桶里可以匹配对应的SQL文本，那么就是软解析，说明之前运行过该sql，其实sql执行期间只要步骤可以跳过，那么我们就可以定位为软解析。这里还有软软解析，这个是最好性能，session_cached_cursors，当会话相同的CURSOR第三次访问是，那么会话会在PGA里做个标记，就算会话结束，cursor也不会从library cache交换出去，这里不需要访问library cache，只和PGA有关联，共享的东西这里我们没去访问，也就是不争用资源，性能得到提升。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle内存碎片]]></title>
    <url>%2F2011%2F09%2F21%2Foracle%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%2F</url>
    <content type="text"><![CDATA[oracle内存碎片是由于频繁的申请，释放，拆分chunk，从而导致拆分成很多小的chunk，这就是内存碎片。碎片有什么危害呢，可能造成shared pool latch的冲突。 我们需要为大的内存需求保留空间，避免申请大chunk的时候，结果没有，申请不到。对于非常大的对象，oracle可以单独保留一个区域为此分配空间，shared_pool_reserved_size，这个值缺省应该是shared_pool_size 的5%，这块区域完全和正常的chunk不相往来，单独存在，v$shared_pool_reserved可以通过这个视图查看这块区域的使用情况。这个区域的管理是先进先出原则，怎么避免内存碎片呢，首先大的对象keep到内存，可以用dbms_shared_pool.keep,具体使用自己研究一下，这里无论是存储对象还是临时的，都可以keep。减少大的匿名块，比如PL/SQL，还有就是避免共享池太大，共享池够用就好，如果共享池很大，小的chunk申请又多，那么就造成很多碎片，freelist就会很长，持有的shared_pool_latch就会时间长，CPU遍历的时候就会很耗资源，所以加大共享池不是解决此种冲突的方法，这个时候最关键的还是看一下为什么不能共享SQL语句。从9I开始，oracle开始引入了多个共享池的概念，所以大的共享池不会再那么差劲，可以最多有7个子latch保护共享池，要配置多个共享池，首先硬件要足够的硬，呵呵。CPU够多，内存够大。比如一个hash桶油18000个chunk，如果只有一个共享池，那么只能遍历这18000个，如果配置了6个子共享池，那么平均一个hash桶就是18000/6，一个shared_pool_latch也就是原来的1/6时间就可以完成。子共享池的个数可以通过隐含参数_kghdsidx_count手动调节，同事也指定了几个child latch，可以通过select a.ksppinm,b.ksppstvl from x$ksppi a,x$ksppsv b where a.indx=b.indx and a.ksppinm=’_kghdsidx_count’;查看你的数据库有几个共享池。看了一下，10G默认的子共享池个数是2个，相对的，增加了共享池，你就可以适当的增加共享池的大小，每个子共享池有自己的LRU列表，和shared_pool_latch.v$db_object_cache存放了钉住的对象信息，或者可以设置cursor_sharing=force.这个设置比较复杂，这里是强制绑定变量，具体以后分解。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux cluster配置安装（简化)]]></title>
    <url>%2F2011%2F09%2F18%2Flinux-cluster%E9%85%8D%E7%BD%AE%E5%AE%89%E8%A3%85%EF%BC%88%E7%AE%80%E5%8C%96%2F</url>
    <content type="text"><![CDATA[首先先介绍一下服务器配置：两台hp ProLiant DL360 G6 ，配置均一样 两颗四核Intel(R) Xeon(R) CPU E5504 @ 2.00GHz 内存：24G 硬盘：三块146G本地硬盘 安装clucster，这一步在安装系统的时候已经选中了cluster组件，如果没有安装，那么安装必要的RPM包利用chkconfig –list查看服务，chkconfig –level 35 service off关闭没有必要的服务，节省资源,提高启动速度配置集群两台服务器都已经安装redhat5.5 下面是进行一些配置文件的修改 首先修改/etc/hosts文件这个文件要求两台机器上均一样 192.168.29.54 pgbouncer-192-168-29-54.sky-mobi.com.hz pgbouncer-192-168-29-54 192.168.29.55 pgbouncer-192-168-29-55.sky-mobi.com.hz pgbouncer-192-168-29-55 192.168.27.8 pgbouncer-192-168-29-55_fence.sky-mobi.com.hz pgbouncer-192-168-29-55_fence 192.168.27.9 pgbouncer-192-168-29-54_fence.sky-mobi.com.hz pgbouncer-192-168-29-54_fence 修改内核参数，不同的硬件配置可以根据具体情况进行配置，以下是我加的/etc/sysctl.confnet.ipv4.ip_local_port_range = 1024 65000 net.core.rmem_default = 1048576 net.core.rmem_max = 1048576 net.core.wmem_default = 262144 net.core.wmem_max = 262144 net.ipv4.tcp_tw_recycle=1 net.ipv4.tcp_max_syn_backlog=4096 net.core.netdev_max_backlog=10000 vm.overcommit_memory=0 net.ipv4.ip_conntrack_max=655360 配置/etc/security/limits.conf,加入12345678* soft nofile 131072* hard nofile 131072* soft nproc 131072* hard nproc 131072* soft core unlimited* hard core unlimited* soft memlock 50000000* hard memlock 50000000 配置/etc/pam.d/login,加入session required pam_limits.so 配置/etc/ssh/sshd_config，加入修改UseDNS no 配置/etc/sysconfig/ntpd，同步改为SYNC_HWCLOCK=yes 配置/etc/rc.local，加入/sbin/sysctl -w net.ipv4.ip_conntrack_max=655360 配置/etc/cluster/cluster.conf,截图有点大，大家凑合着看吧，这里其实就是利用system-config-cluster图形配置完成后生成的集群配置文件，这里直接创建并修改这个文件即可，下面简单说明下这个配置：12345678910111213141516171819202122232425Alias这里是集群的名称，大家可以自定义，不过切记在局域网内保证名字唯一性后面config_version是版本，这个大家修改一次，可以加1，两台服务器要一致，name可以和alias一样。接下来就是配置nodeName是主机名，device name是fence名称&lt;fencedevice agent=&quot;fence_ilo&quot; hostname=&quot;pgbouncer-192-168-29-54_fence&quot; login=&quot;cqzx&quot; name=&quot;pgbouncer-192-168-29-54_fence&quot; passwd=&quot;Fj6Ci0xSKbJ&quot;/&gt;这一行是配置fence，这里是用ilo做fence，填入用户名和密码以及名称即可&lt;failoverdomain name=&quot;pgbouncer_failover&quot; ordered=&quot;0&quot; restricted=&quot;1&quot;&gt; &lt;failoverdomainnode name=&quot;pgbouncer-192-168-29-54&quot; priority=&quot;1&quot;/&gt; &lt;failoverdomainnode name=&quot;pgbouncer-192-168-29-55&quot; priority=&quot;1&quot;/&gt;这里是失效域的配置，failoverdomain name自定义，failoverdomainnode name写入fence设备的名称&lt;ip address=&quot;10.0.0.100&quot; monitor_link=&quot;1&quot;/&gt; &lt;script file=&quot;/etc/init.d/nfs&quot; name=&quot;nfs&quot;/&gt;这里配置资源，这里我是NFS服务&lt;script ref=&quot;nfs&quot;/&gt;这里的名称要与上面name的名称一致 加入crontabCrontab –e /2 /usr/sbin/ntpdate asia.pool.ntp.org &amp;&amp; /sbin/hwclock –systohc 定时同步时间 启动集群服务Service cman start Service rgmanager start 通过clustat查看状态。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[定位library cache lock的方法(转帖)]]></title>
    <url>%2F2011%2F09%2F13%2F%E5%AE%9A%E4%BD%8Dlibrary-cache-lock%E7%9A%84%E6%96%B9%E6%B3%95-%E8%BD%AC%E5%B8%96%2F</url>
    <content type="text"><![CDATA[常用定位library cache lock的方法 经常看到PUB上有兄弟说什么LIBRARY CACHE LOCK和PIN的错误不知道该如何处理，而且定位不到问题出在哪里,我来说几句吧,以我工作上的经验，希望能对大家有用 一般来说,这类错误是因为在包或过程被频繁调用的过程中，DDL语句引起的，那我们该怎么处理呢?其实我们可以这样来操作来查原因，老板要的一般都是为什么产生这个故障和谁操作导致的这个故障，特别是故障处理好后，这个问题就要回答老板了。 1、预先在数据库中建立DDL级的触发器,我认为这个是必要的,因为这个对生产影响不大，但是却可以让我们监控到不少有用的信息.，比如记录在abc表中，可以记录登陆用户，操作语句，操作时间等等信息。 2、在数据库中出现大量的libriary cache lock 的等待事件的时候，系统出现严重的问题了，我们可以立即从这个时间点左右着手，比如12日21日中午12点到12点半之间出问题，如下语句 select * from dba_objects where last_ddl_time&gt;to_date(‘20071221 12:00:00’,’yyyymmdd hh24:mi:ss’) AND last_ddl_time&lt;=to_date(‘200712 12:30:00’,’yyyymmdd hh24:mi:ss’) and (object_type like ‘%PACK%’ or object_type like ‘FUNCTION’ OR object_type=’PROCEDURE’) AND STATUS=’INVALID’ order by last_ddl_time desc 其实通过这个基本上就发现是什么问题了，基本上就只会有一两个对象比如包BBB失效 3、然后找包关联的对象，是否在我们的触发器记录的表中有记录，接着执行如下语句（切记，这个记录DDL动作的语句发挥作用了） select * from abc where ddl_time&gt;to_date(‘20071221 12:00:00’,’yyyymmdd hh24:mi:ss’) AND ddl_time&lt;=to_date(‘200712 12:30:00’,’yyyymmdd hh24:mi:ss’) and schema_object in (SELECT referenced_name FROM DBA_DEPENDENCIES WHERE NAME=’BBB’ ) ORDER BY DDL_time desc （请注意，这个BBB就是上面我查出来的，举例说比如失效的包） 这样查出来的，绝对就是引起这次事故的罪魁祸首的动作了。（ddl_time和 schema_object 是abc表的字段，记录了登陆者操作DDL的时间和对象） 以上方式是我在工作中经常采用的，很好用，一般不会有问题。 当然我上面并没有说明解决问题的方法，解决问题的方法是如下。但是有的时候发现问题原因，追究问题原因是非常非常重要的，可以避免下次再发生，当然通过DUMP systemstate等方式，比较复杂，我的这个思路操作起来应该比较简便，很明了。另外，建立DDL级的触发器，个人认为是必须的！所以上面的方法我想说出来，希望对大家有用！ 解决问题的方法步骤 1、查看具体产生library cache lock 的对象，比如不哪些包和存储过程12345SELECT KGLNAOWN,KGLNAOBJ FROM x$kglob WHERE kglhdadr in( select P1RAW from v$session_wait where event like &apos;library cache%&apos;); 2、 查看具体是那些用户做了这个操作导致 library cache lock123456789select sid, program ,machine from v$session where paddr in ( SELECT s.paddr FROM x$kglpn p, v$session s WHERE p.kglpnuse=s.saddr(+) AND p.kglpnmod &lt;&gt; 0 and kglpnhdl in ( select p1raw from v$session_wait where event in (&apos;library cache pin&apos;,&apos;library cache lock&apos; ,&apos;library cache load lock&apos;) ) ); 3、、以下语句用来杀掉会话（前面查看，然后到这步是决定是否要杀掉进程解决这个问题）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677select &apos;kill -9 &apos;||spid from v$process where addr in ( SELECT s.paddr FROM x$kglpn p, v$session s WHERE p.kglpnuse=s.saddr --AND p.kglpnmod &lt;&gt; 0 and kglpnhdl in ( select p1raw from v$session_wait where event in (&apos; library cache pin&apos;,&apos;library cache lock&apos; ) ) ); 附：DDL触发器的语句 CREATE OR REPLACE TRIGGER tr_trace_ddlAFTER ddlON databaseDECLARE SQL_TEXT ORA_NAME_LIST_T; STATE_SQL VARCHAR2(4000); --DDL$TRACE.DDL_SQL%TYPE; V_ERR_INFO VARCHAR2(200);BEGIN FOR I IN 1 .. ORA_SQL_TXT(SQL_TEXT) LOOP STATE_SQL := STATE_SQL || SQL_TEXT(I); END LOOP; INSERT INTO SYSTEM.ABC (LOGIN_USER, AUDSID, IPADDRESS, SCHEMA_USER, SCHEMA_OBJECT, DDL_TIME, DDL_SQL) VALUES (ORA_LOGIN_USER, USERENV(&apos;SESSIONID&apos;), SYS_CONTEXT(&apos;userenv&apos;, &apos;ip_address&apos;), ORA_DICT_OBJ_OWNER, ORA_DICT_OBJ_NAME, SYSDATE, STATE_SQL);EXCEPTION WHEN OTHERS THEN V_ERR_INFO := SUBSTRB(SQLERRM, 1, 198);END TR_TRACE_DDL; 目的找出spid ,也可以用下面的sql:1234567891011SELECT spid FROM v$process p, v$session s WHERE p.addr = s.paddr AND s.SID IN (SELECT sid FROM v$session_wait b WHERE b.EVENT in (&apos; library cache pin&apos;,&apos;library cache lock&apos; ) ) 前提是sesion 没有被 killed 掉, 如果被killed , v$session.paddr &lt;&gt; v$process.addr.]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle job 失效解决]]></title>
    <url>%2F2011%2F08%2F31%2Foracle-job-%E5%A4%B1%E6%95%88%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[最近一个业务库上的JOB老是没法定时执行，也没有任何错误，今天就抽时间看了一下，应该是JOB失效了 手动执行也可以，用dbms_job.run(:job)也是可以正常执行。 metalink看了一下[ID 313102.1]，下面把具体内容贴一下吧，其实网上也都有的 Check the most common reasons why jobs don’t execute automatically and as scheduled:1) Instance in RESTRICTED SESSIONS mode?Check if the instance is in restricted sessions mode:select instance_name,logins from v$instance;If logins=RESTRICTED, then:alter system disable restricted session;^– Checked! 2) JOB_QUEUE_PROCESSES=0Make sure that job_queue_processes is &gt; 0show parameter job_queue_processes^– Checked! 3) _SYSTEM_TRIG_ENABLED=FALSECheck if _system_enabled_trigger=falsecol parameter format a25col value format a15select a.ksppinm parameter,b.ksppstvl value from x$ksppi a,x$ksppcv bwhere a.indx=b.indx and ksppinm=’_system_trig_enabled’;If _system_trig_enabled=false, thenalter system set “_system_trig_enabled”=TRUE scope=both;^– Checked! 4) Is the job BROKEN?select job,broken from dba_jobs where job=&lt;job_number&gt;;If broken, then check the alert log and trace files to diagnose the issue.^– Checked! The job is not broken. 5) Is the job COMMITted?Make sure a commit is issued after submitting the job:DECLARE X NUMBER;BEGINSYS.DBMS_JOB.SUBMIT(job =&gt; X,what =&gt; ‘dbms_utility.analyze_schema(‘’SCOTT’’,’’COMPUTE’’,NULL,NULL,NULL);’,next_date =&gt; to_date(‘08/06/2005 09:35:00’,’dd/mm/yyyy hh24:mi:ss’),no_parse =&gt; FALSE);COMMIT;END;/If the job executes fine if forced (i.e., exec dbms_jobs.run(&lt;job_no&gt;);), then likely a commitis missing.^– Checked! The job is committed after submission. 6) UPTIME &gt; 497 daysCheck if the server (machine) has been up for more than 497 days:For SUN, use ‘uptime’ OS command.If uptime&gt;497 and the jobs do not execute automatically, then you are hitting unpublished bug 3427424(Jobs may stop running after 497 days uptime) which is fixed in 9206 and A102^– Checked! The server in this case has been up 126 days only 7) DBA_JOBS_RUNNINGCheck dba_jobs_running to see if the job is still running:select * from dba_jobs_running;^– Checked! The job is not running. 8) LAST_DATE and NEXT_DATECheck if the last_date and next_date for the job are proper:select Job,Next_date,Last_date from dba_jobs where job=&lt;job_number&gt;;^– NEXT_DATE is proper, however LAST_DATE is null since the job never executes automatically. 9) NEXT_DATE and INTERVALCheck if the Next_date is changing properly as per the interval set in dba_jobs:select Job,Interval,Next_date,Last_date from dba_jobs where job=&lt;job_number&gt;;^– This is not possible since the job never gets executed automatically. 10) Toggle value for JOB_QUEUE_PROCESSESStop and restart CJQ process(es)alter system set job_queue_processes=0 ;–alter system set job_queue_processes=4 ;Ref: Bug 2649244 (fixed by: 9015, 9203, 10201)^– Done but did not help 11) DBMS_IJOB(Non-documented):Either restart the database or try the following:exec dbms_ijob.set_enabled(true);Ref: Bug 3505718 (Closed, Not a Bug)^– Done but did not help 12) Check view DBA_SCHEDULER_GLOBAL_ATTRIBUTE for CURRENT_OPEN_WINDOW: SQL&gt; select * from DBA_SCHEDULER_GLOBAL_ATTRIBUTE where attribute_name=’CURRENT_OPEN_WINDOW’;If a window is open close it (e.g.):ATTRIBUTE_NAME VALUE CURRENT_OPEN_WINDOW WEEKNIGHT_WINDOW SQL&gt; exec DBMS_SCHEDULER.close_window (‘WEEKNIGHT_WINDOW’);^– Done but did not help These are the most common causes for this behavior. Solution The solution ended up to be the server (machine) uptime.Even though it was up for only 126 days, after the server was rebooted all jobs were able to execute automatically. To implement the solution, please execute the following steps: Shutdown all applications, including databases. Shutdown the server (machine) Restart all applications, including databases. Check that jobs are executing automatically..以上我用了前面几种，都还是无效，最终我是通过[ID 309945.1]解决的： 1) Login as SYS 2) Execute the following command SQL&gt; exec dbms_ijob.set_enabled(true); 3) Verify that kkjsre is set to 1 SQL&gt; oradebug setmypidStatement processed.SQL&gt; oradebug dumpvar sga kkjsreword kkjsre_ [20B7480, 20B7484) = 00000001 4) Verify that jobs are now starting automatically. If not, restart the database and recheck kkjsre. It should still be equal to 1 and jobs should now execute normally. 步骤没几步，很简单。不过如果需要重启库的话，建议在业务低谷的时候操作。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DBA_ERRORS错误一例]]></title>
    <url>%2F2011%2F08%2F25%2FDBA-ERRORS%E9%94%99%E8%AF%AF%E4%B8%80%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[数据库版本10.2.0.4 首先这个东西记录了PL/SQL的一些错误信息，具体含义大家自己网上查查吧 其实这个错误是接着上次expdp的时候出现的，上次执行的脚本： $ORACLE_HOME/rdbms/admin/catmet2.sql$ORACLE_HOME/rdbms/admin/utlrp.sql 首先看一下catmet2.sql 做了些什么 – create the types exec dbms_metadata_build.set_debug(false);exec DBMS_METADATA_DPBUILD.create_table_export;exec DBMS_METADATA_DPBUILD.create_schema_export;exec DBMS_METADATA_DPBUILD.create_database_export;exec DBMS_METADATA_DPBUILD.create_transportable_export; – load XSL stylesheets exec SYS.DBMS_METADATA_UTIL.LOAD_STYLESHEETS; 也只能看到这么多了，这个包是加密的 导致很多type错误，看了看具体的dba_errors错误信息,错误信息基本都是XDB.XDB$RAW_LIST_T和DBMS_RLMGR_DR这两个玩意找不到引起的，XDB是oracle XML database组件里面的，DBMS_RLMGR_DR是oracle rule manager里面的，于是怀疑组件是不是失效了，查了DBA_REGISTRY，果然很多失效组件，而且不只这两个，就连Oracle Database Catalog Views和Oracle Database Packages and Types状态也是INVALID状态，于是先重建了数据字典，也就是catproc.sql和catalog.sql，然后重新编译一下，也就是用这个utlrp.sql。再次查看DBA_REGISTRY，Database Catalog Views，Oracle Database Packages and Types，oracle rule manager都正常了，但是DBA_ERRORS里面还是很多错误信息，关DBMS_RLMGR_DR 的已经木有了，就剩下了XDB.XDB$RAW_LIST_T，说是这个TYPE木有定义，查看DBA_REGISTRY，原来是XML没有安装，ID 1292089.1这篇文章里面很详细，如果有XML，不正常的话，那就重新装一下，装之前，那么要REMOVE一下：1234567891011121314151617181920SQL&gt; spool xdb_removal.logSQL&gt; set echo on;SQL&gt; connect / as sysdbaSQL&gt; shutdown immediate;SQL&gt; startupSQL&gt; @?/rdbms/admin/catnoqm.sqlSQL&gt; @?/rdbms/admin/utlrp.sqlSQL&gt; spool off;然后再安装，没有的话，直接安装即可：SQL&gt; spool xdb_install.logSQL&gt; set echo on;SQL&gt; connect / as sysdbaSQL&gt; shutdown immediate;SQL&gt; startup;SQL&gt; @?/rdbms/admin/catqm.sql &lt;XDB pwd&gt; &lt;XDB default tbs&gt; &lt;XDB temporary tbs&gt;SQL&gt; @?/rdbms/admin/utlrp.sqlSQL&gt; spool off 这里举个例子：SQL&gt; @?/rdbms/admin/catqm.sql XDB XDB TEMP 后面跟这些跟的是XDB的密码，使用表空间以及临时表空间。 这里XML安装好以后，验证一下状态： select comp_name, version, statusfrom dba_registrywhere comp_id = ‘XDB’; 这里我是正常了，但是dba_errors还是依旧错误，依旧还是XDB.XDB$RAW_LIST_T木有定义，这个时候就奇怪了，而且 DESC XDB.XDB$RAW_LIST_T是存在，因为XDB是依赖于oracle intermedia的，于是我再次怀疑是Oracle interMedia有问题，果然状态是INVALID，果断重建。 至于怎么重建，其实也简单，看下这个： more $ORACLE_HOME/ord/im/admin/README.txt 里面很详细记录了怎么重建oracle intermedia 其实就是几个包 @$ORACLE_HOME/ord/admin/ordinst.sql SYSAUX SYSAUX@$ORACLE_HOME/ord/im/admin/iminst.sql 如果没有安装，直接按这个安装即可 如果安装了状态不对，那么先干掉吧 @$ORACLE_HOME/ord/im/admin/imdinst.sql@$ORACLE_HOME/ord/im/admin/imdtyp.sql 用这两个包干掉后，再重建一次，完了用@$ORACLE_HOME/ord/im/admin/imchk.sql验证一下，那么就OK了。 重建以后，问题终于解决了，dba_errors终于没有错误信息了。 我在另一台机器测试运行$ORACLE_HOME/rdbms/admin/catmet2.sql ，是没有问题的，而且那个库只装了数据字典的组件,看来这个包对于其他组件是木有依赖的，只是运行后导致了很多oracle组件失效才引起这么多错误。]]></content>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次expdp错误]]></title>
    <url>%2F2011%2F08%2F24%2F%E8%AE%B0%E4%B8%80%E6%AC%A1expdp%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[话说导数据expdp比exp效率多了，原因很简单，exp是通过BUFFER CACHE的SQL导出到exp文件的，但是expdp则不是，他不通过BUFFER CACHE，而是直接导出到文件的，而且只能在服务端，所以不受网络的影响。 建好相关目录后，就开始动工导数据了，但是出现错误了 expdp mrpmusic/mrpmusic dumpfile=mrpmusic.dmp directory=mrpmusic_expORA-39006: internal errorORA-39065: unexpected master process exception in DISPATCHORA-01403: no data found ORA-39097: Data Pump job encountered unexpected error 100 完了查了下metalink Data Pump Export Started Failing After Applying CPU Patch [ID 453796.1]这篇文章 上面说是运行两个脚本 sqlplus / as sysdba$ORACLE_HOME/rdbms/admin/catmet2.sql$ORACLE_HOME/rdbms/admin/utlrp.sql 执行后，又有新错误 ORA-39125: Worker unexpected fatal error in KUPW$WORKER.UNLOAD_METADATA while calling DBMS_METADATA.FETCH_XML_CLOB [PROCACT_SCHEMA:”MRPMUSIC”]ORA-04063: view “SYS.KU$_CLUSTER_VIEW” has errors ORA-06512: at “SYS.DBMS_SYS_ERROR”, line 105ORA-06512: at “SYS.KUPW$WORKER”, line 6313 继续查看了一下 ID 742018.1 解决方案：12345678910111213cd $ORACLE_HOME/rdbms/adminSQL&gt; startup restrictSQL&gt; select count(*) from dba_objects where status=&apos;INVALID&apos;;SQL&gt; @catalogSQL&gt; @catprocSQL&gt; @utlrp &lt;== To compile the invalid objectsSQL&gt; select count(*) from dba_objects where status=&apos;INVALID&apos;;col comp_id for a12col comp_name for a30col version for a12select comp_id, comp_name, version, status from dba_registry;SQL&gt; shutdown immediateSQL&gt; startup 需要重启数据库，我就不往下继续了。由于版本不同，无法向下兼容，还是老实用低版本的EXP出来]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[INDEX FAST FULL SCAN AND SKIP SCAN]]></title>
    <url>%2F2011%2F08%2F22%2FINDEX-FAST-FULL-SCAN-AND-SKIP-SCAN%2F</url>
    <content type="text"><![CDATA[在快速扫描索引时，oracle读取b-tree索引的所有叶子节点块，而且是顺序读，而且可以同时读取db_file_multiblock_read_count, 而且索引快速扫描比full table scan的物理IO小很多，可以更快的响应请求。以下还是看下原文： The fast full scan can be used if all of the columns in the query for the table are in the indexwith the leading edge of the index not part of the WHERE condition. In the following example, the emp table is used. As shownearlier in this chapter, it has a concatenated index on the columns empno, ename, and deptno. select empno, ename, deptnofrom empwhere deptno = 30; Since all of the columns in the SQL statement are in the index, a fast full scan is available.Index fast full scans are commonly performed during joins in which only the indexed join keycolumns are queried. As an alternative, Oracle may perform a skip-scan access of the index; theoptimizer should consider the histogram for the Deptno column (if one is available) and decidewhich of the available access paths yields the lowest possible performance cost. 既然这里提到了SKIP SCANS,顺别看一下，SKIP SCAN比FAST FULL SCAN INDEX 更快 为了好理解，就拿书中的例子看一下： 这里emp5表有N 万行，建议一个组合索引，如果在查询中不使用引导列作为查询条件，也就是where后面不能有JOB列的限制 优化器为CBO，引导列JOB最好没有重复值，可以强制使用index‘’’create index skip1 on emp5(job,empno);select count(*)from emp5where empno = 7900; Execution Plan0 SELECT STATEMENT Optimizer=CHOOSE (Cost=4 Card=1 Bytes=5)1 0 SORT (AGGREGATE)2 1 INDEX (FAST FULL SCAN) OF ‘SKIP1’ (NON-UNIQUE)Statistics6826 consistent gets6819 physical reads select /+ index(emp5 skip1) / count(*)from emp5where empno = 7900;Elapsed: 00:00:00.56Execution Plan0 SELECT STATEMENT Optimizer=CHOOSE (Cost=6 Card=1 Bytes=5)1 0 SORT (AGGREGATE)2 1 INDEX (SKIP SCAN) OF ‘SKIP1’ (NON-UNIQUE)Statistics21 consistent gets ——–逻辑IO相比较而言小了很多17 physical reads‘’’这里可以看到IO上的区别是很明显的，逻辑IO和物理IO小了很多,有利就有弊，使用SKIP SCAN虽然IO上是有效果，但是CPU的消耗会增加，以上就可以看出，cost变大了，不能盲目使用，以下两个例子CPU COST很明显 使用SKIP SCAN，可以看到逻辑读是比全表扫描少了，CPU cost大了不少 网上有资料说SKIP SCAN是转化为多个SQL union操作，如果前导列重复值很少，将转化为大量的UNION操作，这样效率肯定会低很多。所以前导列重复值多的时候，不会选择skip scan，而且从B-TREE索引的结构看出，确实是选择性越高，那么索引的效果越好。所以一般组合索引，都是选择性高的做为前导列。至于什么时候用skip scan，这个看情况而定了，万事都有个权衡。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TKPROF 使用]]></title>
    <url>%2F2011%2F08%2F18%2FTKPROF-%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[话说oracle的剖析工具有很多，这里就介绍下常用的tkprof剖析工具。敲tkprof回车，可以看到提示Usage: tkprof tracefile outputfile [explain= ] [table= ] [print= ] [insert= ] [sys= ] [sort= ] table=schema.tablename Use ‘schema.tablename’ with ‘explain=’ option. explain=user/password Connect to ORACLE and issue EXPLAIN PLAN. print=integer List only the first ‘integer’ SQL statements. aggregate=yes|no insert=filename List SQL statements and data inside INSERT statements. sys=no TKPROF does not list SQL statements run as user SYS. record=filename Record non-recursive statements found in the trace file. waits=yes|no Record summary for any wait events found in the trace file. sort=option Set of zero or more of the following sort options: prscnt number of times parse was called prscpu cpu time parsing prsela elapsed time parsing prsdsk number of disk reads during parse prsqry number of buffers for consistent read during parse prscu number of buffers for current read during parse prsmis number of misses in library cache during parse execnt number of execute was called execpu cpu time spent executing exeela elapsed time executing exedsk number of disk reads during execute exeqry number of buffers for consistent read during execute execu number of buffers for current read during execute exerow number of rows processed during execute exemis number of library cache misses during execute fchcnt number of times fetch was called fchcpu cpu time spent fetching fchela elapsed time fetching fchdsk number of disk reads during fetch fchqry number of buffers for consistent read during fetch fchcu number of buffers for current read during fetch fchrow number of rows fetched userid userid of user that parsed the cursor 参数是挺多的，这里拣几个常用的理解一下吧 explain这里需要输入用户名和密码 ，explain=user/password，得到执行计划和行源信息 table 指定保存执行计划的表 aggregate 是否单独处理同样内容的SQL waits等待事件是否加入到输出文件 sort指定输出文件的SQL顺序 sys=no 就是不看系统的SQL 参数就介绍这些，下面我们介绍下怎么阅读输出的文本信息，这个才是关键，一般都是udump下的trace文件 tkprof skyread_ora_10409.trc /home/oracle/0818.txt sort=prsela,exeela,fchela print=3 explain=yypt/yypt aggregate=no sys=no 这时上面输出的文件，我来解释下图示可以看出trace file的名称，以及sort的方式，这时是unknown session id，一般这里回显示一个session的id，这个头部信息会出现多次，而且在不同的session之间分隔。count：表示执行的数据库调用数量CPU： 提供执行CPU所花的时间单位是秒Elapsed：提供了执行时所花的时间。单位是秒。这个参数值等于用户响应时间Disk：提供缓存区从磁盘读取的数据块量Query：以一致性模式从缓存区获得数据块的数量Current：以当前模式从缓存区获得数据的块数量ROWs： 返回调用或执行调用时，处理的数据行的数量。这里我们做个试验：create table t1 (a int);insert into t1values (1000); commit;alter session set events ‘10046 trace name context forever,level 12’;select * from t1;update t1 t1_1set x=x+1 ;update t1 t1_2 set x=x+1 ;这样我们就对后面三个sql进行了跟踪。tkprof oradb_ora_25204.trc /home/oracle/zhh.txt explain=charge/charge sys=no可以看到上面三条SQL的信息，还有一定要记得只有加上explain参数，才可以看到执行计划哦。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ONE PASS AND MULTI PASS]]></title>
    <url>%2F2011%2F08%2F01%2FONE-PASS-AND-MULTI-PASS%2F</url>
    <content type="text"><![CDATA[谈到ONE PASS AND MULTI PASS，那么不得不谈谈oracle sort，不知道大家是不是这么认为，给的内存多了，那么SORT是不是就性能就好了呢？答案肯定是否定的，那么我们先介绍下oracle 的SORT。 其实在数据库环境中，很多时候都是伴随着排序的，比如创建索引，group by ,order by,union，分组函数等等。一般情况下，应该是排序在cache中性能是最好的，完了是ONE pass，最差的就是multi pass，但是这不是绝对的，如果你PGA_AGGREGATE_TARGET一味的加大，排序的性能可能直线下降，比MULTI pass的性能还差，在我们OLAP环境中，不要期望所有的排序都在CACHE中，ONE PASS是我们要调优的重点，因为MULTI PASS性能最差。 这里了解一下排序的机制，排序是私有的，他的排序区是有大小限制的，一次排序超过这个限制了，不得不用到临时表空间。监控排序相关的视图：V$SQL_WORKAREA、V$SQL_WORKAREA_ACTIVE、V$SORT_USAGE，这个大家下去自己查阅联机文档从9i开始，workarea_size_policy 是AMM（自动内存管理）AMM会有一个后台进程每3秒钟为检查负载情况，为每个进程合理的更新最小内存ONE-PASS点，所以要找这个点从9i开始就交给oracle自己完成了，我们不需要再去配置sort_area_size等相关的参数。如果workarea_size_policy 是MANUAL的，那么可以研究一下sort_area_size 相关的参数。总的进程PGA大小是由PGA_AGGREGATE_TARGET决定的，其实排序的时候要维护一个二叉树，如果这个二叉树很大的话，那么很消耗CPU资源。 cache模式：当一个排序进程读取数据源，写到workarea_size_policy 的时候，incoming data和tree没有被填充满就结束了排序的情况，就是cache模式，这种是性能最好的情况。 one-pass模式：当一个排序吧incoming data和tree填充满以后，如果再继续填充，那么会把工作区里面的数据进行分片，叫sort runs，这个排序运行片归档至临时表空间。那么如果排序很大，就会有很多的sort runs，归档到临时表空间的sort runs还的重新进行一次merge，这里有一个基于排序区的宽度（max intermediate merge width），也就是一次merge的宽度，可以通过10032和10033查看这些内容，比如这里有50个sort runs，这个宽度是100，那么我们merge一次就可以完成，这里就叫做one-pass。 multi-pass模式：如果merge一次，不够，需要多次merge。多次merge，肯定增加IO压力。所以这种是效率最差的。 当做工作区是AMM的时候，如果不能cache，那么就要切换到minimum one-pass memeory.这里只介绍几种模式，具体优化以后有时间再续。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle ORA-1555错误]]></title>
    <url>%2F2011%2F07%2F29%2Foracle-ORA-1555%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[1555错误大家应该都碰到过，这里做下简单的阐述和一些解决方法。 大家可以这么理解，oracle提交的UNDO超过了保留期，或者在保留期的数据被覆盖，无法做一致性读，就会抛出此类错误，这里有几个参数有必要说明一下： UNDO_MANAGEMENT：值为AUTO表示使用了自动撤销管理表空间，MANUAL则表示手动管理（已淘汰），如果想Flashback Query自动管理必须条件 。 UNDO_TABLESPACE：Oracle数据库中可以创建多个UNDO表空间，不过同时只能使用一个，当UNDO_MANAGEMENT初始化参数值为AUTO时，UNDO_TABLESPACE参数用来指定当前使用的UNDO表空间名称 UNDO_RETENTION：该参数用来指定UNDO段中数据保存的最短时间，以秒为单位，是一个动态参数，完全可以在实例运行时随时修改，通常默认是900秒，其实这个保留时间并不是说超过这个时间就会过期，数据就不在了，只是标记了一下可以被覆盖了，超过这个时间的数据可以被覆盖了，同理，就算是没有超过这个时间，你的UNDO空间已经满了，那么新事务的数据还是会覆盖掉UNDO。那么此时如果你在找丢失部分的数据，就会出现ORA 1555了，简单点来说就是找不到UNDO里面的前镜像了。 另外块清除会引起1555，不过这种情况是很少遇到的。 可以show parameter undo看一下这几个参数的值。 还有如果你的UNDO表空间过于小，那可能一般的普通操作都会报出这个错，大家一定要设置合理，避免此类错误。 哈哈，既然关系到UNDO，那么再简单说下UNDO吧，首先有几个数据字典和动态性能视图：v$undostat,DBA_ROLLBACK_SEGS,DBA_UNDO_EXTENTS,还有一个v$TRANSACTION，记录了事务的一些信息，还有回滚的数量。 UNDO其实就是记录删除或者更新操作的数据，顾名思义就是为了回滚，这里和REDO是紧密相连的，这里涉及到UNDO的REDO,因为事务其实都是先写UNDO，再写REDO的，也就是UNDO的REDO（记录UNDO块的修改）和REDO的redo（记录普通数据文件的修改）是所有的REDO。那么UNDO这里只是做一个简单的了解。 大家一定要记得在insert的时候，如果列上有索引，即使nologging，那么还是会导致大量的UNDO，因为在插入数据的时候会调整索引，那么肯定会产生大量的UNDO。delete和update是必走内存的，所以始终还是会记录REDO。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle listener]]></title>
    <url>%2F2011%2F07%2F21%2Foracle-listener%2F</url>
    <content type="text"><![CDATA[这一块知识，我相信搞oracle的兄弟都是比较精通的，我也是前段时间公司让做个培训的时候，又把这块又温习了一遍，还是有不少新的收获，今天就搬到这里记录一下大家可以看到这里的WEB应用充当中间件，既懂HTTP，又懂oracle net，厉害吧，其实就是个翻译官。如果WEB应用服务器采用 JDBC OCI DRIVER，那么WEB服务必须的安装oracle net组件，才能和oracle数据库进行通讯，走的TCP/IP协议。如果WEB应用服务是JDBC THIN DRIVER，也就是瘦客户端，那么不需要oracle net组件，只需要配置JAVA NET就可以和oracle进行通讯。监听怎么响应连接呢？看下图：衍生继承模式：当有连接请求时，listener接待，触发一个服务器进程，红框内3直接继承了listener，只能用在专有模式，listener关闭了不影响直接传送：使用Oracle Shared Server 时，监听程序将把连接传送给调度程序。专有模式不可用 重定向：listener和服务端不在同一台机器，比如RAC和共享服务 静态注册和动态注册： 1.动态注册：就是PMON主动把信息告诉监听，无需使用listener.ora将文件，lsnrclt status里面read的都是动态。 2.静态注册：监听主动去找服务和实例，需要配置listener.ora文件，指定SID列表，lsnrctl status里面是unknown 先看静态注册，很简单的，保证一看就懂 123456789101112131415161718192021222324252627直接配置listener.ora文件即可SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = oradb) (ORACLE_HOME = /app/oracle/product/10.2.0/db_1) ) )LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST =)(PORT = 1521)) ) ) 需要配置SID_NAME LISTENER需要指定相关参数块，这里如果host参数不指定，那么/etc/hosts需要指定，监听启动的时候回去读hosts文件匹配，如果设置为0.0.0.0，那么默认监听所有地址 动态注册以及配置： 1.动态注册不需要配置listener.ora文件，需要配置初始化参数文件，参数service_names,可是设置多个服务名，区分不同业务。 2.如果想配置非默认端口，非默认监听名称，非TCPIP协议，那么需要配置listener.ora 而且需要配置local_listener参数，tnsnames.ora也需要配置。 这里可以看到动态注册分为默认的和非默认的，默认的就是TCP/IP协议，端口是1521，监听名称LISTENER。非默认的大家自己能理解的哦。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748默认动态注册实验：1.Show parameter service_names;2.Alter system set service_names=zhang,hai,hong;3. Mv listener.ora listener.ora.bak Lsnrctl stop4.Lsnrctl start5.Alter system register;6.Lsnrctl service;看结果：Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=172.16.3.174)(PORT=1521)))Services Summary...Service &quot;HAI&quot; has 1 instance(s). Instance &quot;oradb&quot;, status READY, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 state:ready LOCAL SERVERService &quot;HONG&quot; has 1 instance(s). Instance &quot;oradb&quot;, status READY, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 state:ready LOCAL SERVERService &quot;ZHANG&quot; has 1 instance(s). Instance &quot;oradb&quot;, status READY, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 state:ready LOCAL SERVERService &quot;oradb&quot; has 2 instance(s). Instance &quot;oradb&quot;, status UNKNOWN, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 LOCAL SERVER Instance &quot;oradb&quot;, status READY, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 state:ready LOCAL SERVERService &quot;oradb_XPT&quot; has 1 instance(s). Instance &quot;oradb&quot;, status READY, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 state:ready LOCAL SERVERThe command completed successfully 相应的client端你如果是用oracle net组件的，那么肯定要配置tnsnames.ora文件123456789101112131415testdb =(DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 172.168.3.174)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = zhang) )) 注意：标红的可以写zhang,hai,hong 或者oradb，就算木有listener.ora 文件，照样可以监听。 下面介绍下非默认动态注册： 这里我们端口用1234,非默认必须需要listener.ora 文件，还有就是local_listener参数. 修改监听文件：1234567891011121314151617# listener.ora Network Configuration File: /app/oracle/product/10.2.0/db_1/network/admin/listener.ora# Generated by Oracle configuration tools.SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = oradb) (ORACLE_HOME = /app/oracle/product/10.2.0/db_1) ) )LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST =172.16.3.174)(PORT = 1234)) ) ) 修改local_listener参数：Alter system set local_listener=‘(ADDRESS = (PROTOCOL = TCP)(HOST =)(PORT = 1234))’; 注意这里，以上修改参数等同于以下配置： 配置服务端的tnsnames.ora文件1234567891011hankzhang =(DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST =)(PORT = 1234)) )) 然后再设置参数： Alter system set local_listener=hankzhang; 以上两种方法效果是一样滴。 lisnrctl status看一下：至于RAC的listener配置，呵呵，大同小异，不过还是有区别的，这里先提以下，有时间再继续。 RAC在监听端也可以负载均衡的哦，呵呵，当然这是在RAC双主模式的情况下，而且需要配置REMOTE_LISTENER，配置tnsnames.ora文件，监听暂时先到这里。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Installation from Source Code for postgreSQL]]></title>
    <url>%2F2010%2F09%2F18%2FInstallation-from-Source-Code-for-postgreSQL%2F</url>
    <content type="text"><![CDATA[其实学习pg有一段时间了，不过一直没有写相关的blog，以后这一块也会一起加进来，记录自己的学习过程。这里就先介绍下安装吧，pg安装还是很简单的，而且速度也快。1.和其他数据库安装一样，可以根据自己的需求，修改系统参数 /etc/sysctl.conf ,/etc/security/limits.conf,2.新建用户和组： #groupadd postgres #useradd -g postgres postgres3.创建相关目录： mkdir -p /database/pgdata/pg_root mkdir -p /opt/pgsql chown -R postgres:postgres /database/pgdata/pg_root 4.配置环境变量export PS1=”$USER@/bin/hostname -s-&gt; “export PGPORT=1921export PGDATA= /database/pgdata/pg_rootexport LANG=en_US.utf8export PGHOME=/opt/pgsqlexport LD_LIBRARY_PATH=$PGHOME/lib:/lib64:/usr/lib64:/usr/local/lib64:/lib:/usr/lib:/usr/local/libexport DATE=date +&quot;%Y%m%d%H%M&quot;export PATH=$PGHOME/bin:$PATH:.export MANPATH=$PGHOME/share/man:$MANPATHalias rm=’rm -i’alias ll=’ls -lh’根据自己需求自己修改5.解压安装包，可以安装了 ./configure –help这个可以查看一下对应的帮助，根据自己的环境，适当选用一些参数./configure –prefix=/opt/pgsql –with-pgport=1921 –with-segsize=8 –with-wal-segsize=64 –with-wal-blocksize=64 –with-perl –with-python –with-openssl –with-pam –with-ldap –with-libxml –with-libxslt –enable-thread-safety gmake worldgmake install-world安装完成以后su - postgresinitdb -D /database/pgdata/pg_root初始化以后，可以启动数据库了通过postgres -D 或者pg_ctl -D后面跟对应的安装路径就可以了。]]></content>
      <categories>
        <category>PostgreSQL</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
      </tags>
  </entry>
</search>
