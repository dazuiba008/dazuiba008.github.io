<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Installation from Source Code for postgreSQL]]></title>
    <url>%2F2018%2F09%2F18%2FInstallation-from-Source-Code-for-postgreSQL%2F</url>
    <content type="text"><![CDATA[其实学习pg有一段时间了，不过一直没有写相关的blog，以后这一块也会一起加进来，记录自己的学习过程。这里就先介绍下安装吧，pg安装还是很简单的，而且速度也快。1.和其他数据库安装一样，可以根据自己的需求，修改系统参数 /etc/sysctl.conf ,/etc/security/limits.conf,2.新建用户和组： #groupadd postgres #useradd -g postgres postgres3.创建相关目录： mkdir -p /database/pgdata/pg_root mkdir -p /opt/pgsql chown -R postgres:postgres /database/pgdata/pg_root 4.配置环境变量export PS1=”$USER@/bin/hostname -s-&gt; “export PGPORT=1921export PGDATA= /database/pgdata/pg_rootexport LANG=en_US.utf8export PGHOME=/opt/pgsqlexport LD_LIBRARY_PATH=$PGHOME/lib:/lib64:/usr/lib64:/usr/local/lib64:/lib:/usr/lib:/usr/local/libexport DATE=date +&quot;%Y%m%d%H%M&quot;export PATH=$PGHOME/bin:$PATH:.export MANPATH=$PGHOME/share/man:$MANPATHalias rm=’rm -i’alias ll=’ls -lh’根据自己需求自己修改5.解压安装包，可以安装了 ./configure –help这个可以查看一下对应的帮助，根据自己的环境，适当选用一些参数./configure –prefix=/opt/pgsql –with-pgport=1921 –with-segsize=8 –with-wal-segsize=64 –with-wal-blocksize=64 –with-perl –with-python –with-openssl –with-pam –with-ldap –with-libxml –with-libxslt –enable-thread-safety gmake worldgmake install-world安装完成以后su - postgresinitdb -D /database/pgdata/pg_root初始化以后，可以启动数据库了通过postgres -D 或者pg_ctl -D后面跟对应的安装路径就可以了。]]></content>
      <categories>
        <category>PostgreSQL</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Greenplum install]]></title>
    <url>%2F2018%2F09%2F18%2FGreenplum-install%2F</url>
    <content type="text"><![CDATA[架构：master主要建立与客户端的连接，收集segment的执行结果，不存放业务数据，可以一主一备segment业务数据存放处，执行master分发的SQL,一台机器可以配置多个segment，segment分primary和mirror 四台服务器搭建测试环境 192.168.101.115 master192.168.101.116 segment+standby192.168.100.217 segment192.168.100.225 segment 分辨配置一个primary，一个mirror对应后面参数路径，如果设置多个,空格分隔即可declare -a DATA_DIRECTORY=(/data01/gpadmin/gpdata/primary)declare -a MIRROR_DATA_DIRECTORY=(/data01/gpadmin/gpdata/mirror) 1.每台服务器/etc/hosts192.168.101.115 db-192-168-101-115.sky-mobi.com db-192-168-101-115192.168.101.116 db-192-168-101-116.sky-mobi.com db-192-168-101-116192.168.100.217 db-192-168-100-217.sky-mobi.com db-192-168-100-217192.168.100.225 db-192-168-100-225.sky-mobi.com db-192-168-100-225 2.配置/etc/sysctl.confkernel.shmmax = 500000000kernel.shmmni = 4096kernel.shmall = 4000000000kernel.sem = 250 512000 100 2048kernel.sysrq = 1kernel.core_uses_pid = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.msgmni = 2048net.ipv4.tcp_syncookies = 1net.ipv4.conf.default.accept_source_route = 0net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_max_syn_backlog = 4096net.ipv4.conf.all.arp_filter = 1net.ipv4.ip_local_port_range = 10000 65535net.core.netdev_max_backlog = 10000net.core.rmem_max = 2097152net.core.wmem_max = 2097152vm.overcommit_memory = 2 3.配置/etc/security/limits.conf soft nofile 65536 hard nofile 65536 soft nproc 131072 hard nproc 131072 修改磁盘调度策略echo deadline &gt; /sys/block/sba/queue/scheduler 5.执行安装程序useradd gpadminpasswd gpadminunzip greenplum-db-4.3.12.0-rhel5-x86_64.zip./greenplum-db-4.3.12.0-rhel5-x86_64.bin默认安装在/usr/local下 7.chown -R gpadmin.gpadmin /usr/local/greenplum-db8.配置gpadmin环境变量，添加以下source /usr/local/greenplum-db/greenplum_path.shexport MASTER_DATA_DIRECTORY=/data01/gpadmin/gpdata/master/gpseg-1export PGPORT=1922export PS1=”$USER@/bin/hostname -s-&gt; “ 9.新建两个文件hostlist, seg_hostshostlistdb-192-168-101-115db-192-168-101-116db-192-168-100-217db-192-168-100-225 seg_hostsdb-192-168-101-116db-192-168-100-217db-192-168-100-225 10.使用gpssh-exkeys打通所有服务器的透明登陆gpssh-exkeys -f hostlistgpssh -f hostlist ls //批量执行命令 11.打包安装好的目录，并复制到其他节点，解压tar -cf gp.tar /use/local/greenplum-db-4.3.12.0/gpscp -f hostlist gp.tar =:/home/gpmadin //批量服务到每个节点tar -xf gp.tar //解压 12.建立相关数据目录赋予权限mkdir -p /data01/gpadmin/gpdata/mastermkdir -p /data01/gpadmin/gpdata/primarymkdir -p /data01/gpadmin/gpdata/mirrorchown -R gpadmin.gpadmin /data01/gpadmin/gpdata/master /data01/gpadmin/gpdata/primary /data01/gpadmin/gpdata/mirror 13.初始化Greenplum复制配置文件到自己的目录cp /usr/local/greenplum-db/docs/cli_help/gpconfigs/gpinitsystem_config /home/gpadmin/ 修改后的相关参数ARRAY_NAME=”SKY Greenplum DW”SEG_PREFIX=gpsegPORT_BASE=40000declare -a DATA_DIRECTORY=(/data01/gpadmin/gpdata/primary)MASTER_HOSTNAME=db-192-168-101-115MASTER_DIRECTORY=/data01/gpadmin/gpdata/masterMASTER_PORT=1922TRUSTED_SHELL=sshCHECK_POINT_SEGMENTS=8ENCODING=UTF-8MIRROR_PORT_BASE=50000REPLICATION_PORT_BASE=41000MIRROR_REPLICATION_PORT_BASE=51000declare -a MIRROR_DATA_DIRECTORY=(/data01/gpadmin/gpdata/mirror)MACHINE_LIST_FILE=/home/gpadmin/seg_hosts 初始化GPgpinitsystem -c /home/gpadmin/gpinitsystem_config -s db-192-168-101-116 数据库可以正常连接：psql -d postgrespsql (8.2.15)Type “help” for help. postgres=# \l List of databases Name | Owner | Encoding | Access privileges———–+———+———-+———————— hank | gpadmin | UTF8 | =Tc/gpadmin : gpadmin=CTc/gpadmin : hank=CTc/gpadmin postgres | gpadmin | UTF8 | template0 | gpadmin | UTF8 | =c/gpadmin : gpadmin=CTc/gpadmin template1 | gpadmin | UTF8 | =c/gpadmin : gpadmin=CTc/gpadmin 关闭与启动： gpstart -a 启动 gpstop -a 关闭 gpstop -r 重启 gpstop -u 重载配置参数 gpstart -m 单用户维护模式启动 PGOPTIONS=’-c gp_session_role=utility’ psql gpstate 查看GP状态 参考：http://gpdb.docs.pivotal.io/43120/install_guide/prep_os_install_gpdb.html]]></content>
      <categories>
        <category>Greenplum</category>
      </categories>
      <tags>
        <tag>Greenplum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb replica sets reconfig and conver a Secondary to an Arbiter]]></title>
    <url>%2F2013%2F04%2F22%2Fmongodb-replica-sets-reconfig-and-conver-a-Secondary-to-an-Arbiter%2F</url>
    <content type="text"><![CDATA[replica set由于需求可能会调整节点的优先级，或者仲裁节点那么先看一下语法：rs.reconfig(configuration[, force])Parameters:configuration – A document that specifies the configuration of a replica set.force – Optional. Specify { force: true } as the force parameter to force the replica set to accept the new configuration even if a majority of the members are not accessible. Use with caution, as this can lead to rollback situations.Initializes a new replica set configuration. This function will disconnect the shell briefly and forces a reconnection as the replica set renegotiates which node will be primary. As a result, the shell will display an error even if this command succeeds. rs.reconfig() provides a wrapper around the “replSetReconfig” database command. rs.reconfig() overwrites the existing replica set configuration. Retrieve the current configuration object with rs.conf(), modify the configuration as needed and then use rs.reconfig() to submit the modified configuration object. To reconfigure a replica set, use the following sequence of operations: conf = rs.conf() // modify conf to change configuration rs.reconfig(conf)If you want to force the reconfiguration if a majority of the set isn’t connected to the current member, or you’re issuing the command against a secondary, use the following form: conf = rs.conf() // modify conf to change configuration rs.reconfig(conf, { force: true } )Warning Forcing a rs.reconfig() can lead to rollback situations and other difficult to recover from situations. Exercise caution when using this option.这里遇到rollback情况，可能会导致fatal状态，那么replica set就等于失效了，可以拷贝local数据文件，或者所有数据文件进行重建举例：var c = rs.conf();c.members[2].priority = 0; 0~100数字越大优先级越高，0不会被切换为primary节点，这里也可以写成包含小数的值rs.reconfig(c);配置完以后，可以通过一下命令查看一下配置是否修改好：rs.conf()rs.status()为了防止脑裂，可以加入仲裁节点，使用以下命令：rs.addArb(“:&lt;:port&gt;”); ==rs.add(hostspec, arbiterOnly)示例：rs.add(‘mongodb3.example.net:27017’, true)当然将一个从节点转换为仲裁节点：(1)首先关闭从节点(2)rs.remove(“&lt;:port&gt;”)删除该从节点，rs.conf()验证一下(3)创建新的数据目录，因为仲裁节点是不存放生产数据的(4)通过rs.addArb(“:&lt;:port&gt;”)加入，rs.conf()验证一下那么就可以看到：仲裁节点的属性为”arbiterOnly” : true{ “_id” : “xxx”, “version” : 14, “members” : [ { “_id” : 1, “host” : “xxx.xxx.xxx.xxx:5281” }, { “_id” : 2, “host” : “ xxx.xxx.xxx.xxx :5281”, “arbiterOnly” : true }, { “_id” : 3, “host” : “ xxx.xxx.xxx.xxx :5281” } ]}]]></content>
      <categories>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle内存碎片]]></title>
    <url>%2F2011%2F09%2F21%2Foracle%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%2F</url>
    <content type="text"><![CDATA[oracle内存碎片是由于频繁的申请，释放，拆分chunk，从而导致拆分成很多小的chunk，这就是内存碎片。碎片有什么危害呢，可能造成shared pool latch的冲突。 我们需要为大的内存需求保留空间，避免申请大chunk的时候，结果没有，申请不到。对于非常大的对象，oracle可以单独保留一个区域为此分配空间，shared_pool_reserved_size，这个值缺省应该是shared_pool_size 的5%，这块区域完全和正常的chunk不相往来，单独存在，v$shared_pool_reserved可以通过这个视图查看这块区域的使用情况。这个区域的管理是先进先出原则，怎么避免内存碎片呢，首先大的对象keep到内存，可以用dbms_shared_pool.keep,具体使用自己研究一下，这里无论是存储对象还是临时的，都可以keep。减少大的匿名块，比如PL/SQL，还有就是避免共享池太大，共享池够用就好，如果共享池很大，小的chunk申请又多，那么就造成很多碎片，freelist就会很长，持有的shared_pool_latch就会时间长，CPU遍历的时候就会很耗资源，所以加大共享池不是解决此种冲突的方法，这个时候最关键的还是看一下为什么不能共享SQL语句。从9I开始，oracle开始引入了多个共享池的概念，所以大的共享池不会再那么差劲，可以最多有7个子latch保护共享池，要配置多个共享池，首先硬件要足够的硬，呵呵。CPU够多，内存够大。比如一个hash桶油18000个chunk，如果只有一个共享池，那么只能遍历这18000个，如果配置了6个子共享池，那么平均一个hash桶就是18000/6，一个shared_pool_latch也就是原来的1/6时间就可以完成。子共享池的个数可以通过隐含参数_kghdsidx_count手动调节，同事也指定了几个child latch，可以通过select a.ksppinm,b.ksppstvl from x$ksppi a,x$ksppsv b where a.indx=b.indx and a.ksppinm=’_kghdsidx_count’;查看你的数据库有几个共享池。看了一下，10G默认的子共享池个数是2个，相对的，增加了共享池，你就可以适当的增加共享池的大小，每个子共享池有自己的LRU列表，和shared_pool_latch.v$db_object_cache存放了钉住的对象信息，或者可以设置cursor_sharing=force.这个设置比较复杂，这里是强制绑定变量，具体以后分解。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ONE PASS AND MULTI PASS]]></title>
    <url>%2F2011%2F08%2F01%2FONE-PASS-AND-MULTI-PASS%2F</url>
    <content type="text"><![CDATA[谈到ONE PASS AND MULTI PASS，那么不得不谈谈oracle sort，不知道大家是不是这么认为，给的内存多了，那么SORT是不是就性能就好了呢？答案肯定是否定的，那么我们先介绍下oracle 的SORT。 其实在数据库环境中，很多时候都是伴随着排序的，比如创建索引，group by ,order by,union，分组函数等等。一般情况下，应该是排序在cache中性能是最好的，完了是ONE pass，最差的就是multi pass，但是这不是绝对的，如果你PGA_AGGREGATE_TARGET一味的加大，排序的性能可能直线下降，比MULTI pass的性能还差，在我们OLAP环境中，不要期望所有的排序都在CACHE中，ONE PASS是我们要调优的重点，因为MULTI PASS性能最差。 这里了解一下排序的机制，排序是私有的，他的排序区是有大小限制的，一次排序超过这个限制了，不得不用到临时表空间。监控排序相关的视图：V$SQL_WORKAREA、V$SQL_WORKAREA_ACTIVE、V$SORT_USAGE，这个大家下去自己查阅联机文档从9i开始，workarea_size_policy 是AMM（自动内存管理）AMM会有一个后台进程每3秒钟为检查负载情况，为每个进程合理的更新最小内存ONE-PASS点，所以要找这个点从9i开始就交给oracle自己完成了，我们不需要再去配置sort_area_size等相关的参数。如果workarea_size_policy 是MANUAL的，那么可以研究一下sort_area_size 相关的参数。总的进程PGA大小是由PGA_AGGREGATE_TARGET决定的，其实排序的时候要维护一个二叉树，如果这个二叉树很大的话，那么很消耗CPU资源。 cache模式：当一个排序进程读取数据源，写到workarea_size_policy 的时候，incoming data和tree没有被填充满就结束了排序的情况，就是cache模式，这种是性能最好的情况。 one-pass模式：当一个排序吧incoming data和tree填充满以后，如果再继续填充，那么会把工作区里面的数据进行分片，叫sort runs，这个排序运行片归档至临时表空间。那么如果排序很大，就会有很多的sort runs，归档到临时表空间的sort runs还的重新进行一次merge，这里有一个基于排序区的宽度（max intermediate merge width），也就是一次merge的宽度，可以通过10032和10033查看这些内容，比如这里有50个sort runs，这个宽度是100，那么我们merge一次就可以完成，这里就叫做one-pass。 multi-pass模式：如果merge一次，不够，需要多次merge。多次merge，肯定增加IO压力。所以这种是效率最差的。 当做工作区是AMM的时候，如果不能cache，那么就要切换到minimum one-pass memeory.这里只介绍几种模式，具体优化以后有时间再续。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle ORA-1555错误]]></title>
    <url>%2F2011%2F07%2F29%2Foracle-ORA-1555%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[1555错误大家应该都碰到过，这里做下简单的阐述和一些解决方法。 大家可以这么理解，oracle提交的UNDO超过了保留期，或者在保留期的数据被覆盖，无法做一致性读，就会抛出此类错误，这里有几个参数有必要说明一下： UNDO_MANAGEMENT：值为AUTO表示使用了自动撤销管理表空间，MANUAL则表示手动管理（已淘汰），如果想Flashback Query自动管理必须条件 。 UNDO_TABLESPACE：Oracle数据库中可以创建多个UNDO表空间，不过同时只能使用一个，当UNDO_MANAGEMENT初始化参数值为AUTO时，UNDO_TABLESPACE参数用来指定当前使用的UNDO表空间名称 UNDO_RETENTION：该参数用来指定UNDO段中数据保存的最短时间，以秒为单位，是一个动态参数，完全可以在实例运行时随时修改，通常默认是900秒，其实这个保留时间并不是说超过这个时间就会过期，数据就不在了，只是标记了一下可以被覆盖了，超过这个时间的数据可以被覆盖了，同理，就算是没有超过这个时间，你的UNDO空间已经满了，那么新事务的数据还是会覆盖掉UNDO。那么此时如果你在找丢失部分的数据，就会出现ORA 1555了，简单点来说就是找不到UNDO里面的前镜像了。 另外块清除会引起1555，不过这种情况是很少遇到的。 可以show parameter undo看一下这几个参数的值。 还有如果你的UNDO表空间过于小，那可能一般的普通操作都会报出这个错，大家一定要设置合理，避免此类错误。 哈哈，既然关系到UNDO，那么再简单说下UNDO吧，首先有几个数据字典和动态性能视图：v$undostat,DBA_ROLLBACK_SEGS,DBA_UNDO_EXTENTS,还有一个v$TRANSACTION，记录了事务的一些信息，还有回滚的数量。 UNDO其实就是记录删除或者更新操作的数据，顾名思义就是为了回滚，这里和REDO是紧密相连的，这里涉及到UNDO的REDO,因为事务其实都是先写UNDO，再写REDO的，也就是UNDO的REDO（记录UNDO块的修改）和REDO的redo（记录普通数据文件的修改）是所有的REDO。那么UNDO这里只是做一个简单的了解。 大家一定要记得在insert的时候，如果列上有索引，即使nologging，那么还是会导致大量的UNDO，因为在插入数据的时候会调整索引，那么肯定会产生大量的UNDO。delete和update是必走内存的，所以始终还是会记录REDO。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
</search>
